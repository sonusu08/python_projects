{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a Python Web Scraping Project From Scratch\n",
    "\n",
    "This project guide is a part of the [Zero to Data Analyst Bootcamp by Jovian](https://www.jovian.ai/data-analyst-bootcamp).\n",
    "\n",
    "![](https://i.imgur.com/6zM7JBq.png)\n",
    "\n",
    "Web scraping is the process of extracting and parsing data from websites in an automated fashion using a computer program. It's a useful technique for creating datasets for research and learning. Follow these steps to build a web scraping project from scratch using Python and its ecosystem of libraries:\n",
    "\n",
    "1. **Pick a website and describe your objective**\n",
    "\n",
    "    - Browse through different sites and pick on to scrape. Check the \"Project Ideas\" section for inspiration.\n",
    "    - Identify the information you'd like to scrape from the site. Decide the format of the output CSV file.\n",
    "    - Summarize your project idea and outline your strategy in a Juptyer notebook. Use the \"New\" button above.\n",
    "\n",
    "\n",
    "2. **Use the requests library to download web pages**\n",
    "\n",
    "    - Inspect the website's HTML source and identify the right URLs to download.\n",
    "    - Download and save web pages locally using the `requests` library.\n",
    "    - Create a function to automate downloading for different topics/search queries.\n",
    "\n",
    "\n",
    "3. **Use Beautiful Soup to parse and extract information**\n",
    "\n",
    "    - Parse and explore the structure of downloaded web pages using Beautiful soup.\n",
    "    - Use the right properties and methods to extract the required information.\n",
    "    - Create functions to extract from the page into lists and dictionaries.\n",
    "    - (Optional) Use a REST API to acquire additional information if required.\n",
    "\n",
    "\n",
    "4. **Create CSV file(s) with the extracted information**\n",
    "\n",
    "    - Create functions for the end-to-end process of downloading, parsing, and saving CSVs.\n",
    "    - Execute the function with different inputs to create a dataset of CSV files.\n",
    "    - Verify the information in the CSV files by reading them back using [Pandas](https://pandas.pydata.org).\n",
    "\n",
    "\n",
    "5. **Document and share your work**\n",
    "\n",
    "    - Add proper headings and documentation in your Jupyter notebook.\n",
    "    - Publish your Jupyter notebook to your [Jovian profile](https://jovian.ai/aakashns)\n",
    "    - (Optional) Write a blog post about your project and share it online.\n",
    "\n",
    "\n",
    "**Notes**\n",
    "\n",
    "* Use the \"New\" button on [Jovian](https://jovian.ai) to create a new notebook, and select \"Run on Binder\" to get started.\n",
    "\n",
    "* Follow this tutorial to learn web scraping: https://jovian.ai/aakashns/python-web-scraping-and-rest-api\n",
    "\n",
    "* Check out 20-week bootcamp to learn Python programming, web scraping, data analysis and more: http://zerotoanalyst.com\n",
    "\n",
    "Tweet your projects and tag [@JovianML](https://twitter.com/jovianml). We're retweeting 3 interesting proejcts everyday!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Ideas\n",
    "\n",
    "Here are some project ideas to get you started. You can work of one of these ideas, or pick something entirely different.\n",
    "\n",
    "\n",
    "1. **Filmography of Actors/Directors (Wikipedia)**: The list of Films and TV shows an actor has been a part of is called their filmography. Here's an example filmography page on Wikipedia: https://en.wikipedia.org/wiki/Christian_Bale_filmography . Can you scrape this information and create a dataset of [filmographies](https://en.wikipedia.org/wiki/Category:American_filmographies) of famous actors/actresses/directors with information like film title, year of release, etc.? \n",
    "\n",
    "\n",
    "2. **Discography of an Artist (Wikipedia)**: The list of albums released by an artist is called their discography. Here's an example discography page on Wikipedia: https://en.wikipedia.org/wiki/Linkin_Park_discography . Can you scrape this information and create a dataset of [discographies](https://en.wikipedia.org/wiki/Linkin_Park_discography) or music albums with information like the album title, release date etc.?\n",
    "\n",
    "\n",
    "3. **Dataset of Movies (TMDb)**: The Movie Database (TMDb) contains information about thousands of movies from around the world: https://www.themoviedb.org/movie . Can you scape the site to create a dataset of movies containing information like title, release date, cast, etc. ? You can also create datasets of movie actors/actresses/directors using this site.\n",
    "\n",
    "\n",
    "4. **Dataset of TV Shows (TMDb)**: The Movie Database (TMDb) contains information about thousands of TV shows from around the world: https://www.themoviedb.org/tv . Can you scape the site to create a dataset of TV shows containing information like title, release date, cast, crew, etc. ? You can also create datasets of TV actors/actresses/directors using this site.\n",
    "\n",
    "\n",
    "5. **Collections of Popular Repositories (GitHub)**: Scape GitHub collections ( https://github.com/collections ) to create a dataset of popular repositories organized by different use cases.\n",
    "\n",
    "\n",
    "6. **Dataset of Books (BooksToScrape)**: Create a dataset of popular books in different genres by scraping the site *Books To Scrape*: http://books.toscrape.com\n",
    "\n",
    "\n",
    "7. **Dataset of Quotes (QuotesToScrape)**: Create a dataset of popular quotes for different tags by scraping the site *Quotes To Scrape*: http://quotes.toscrape.com\n",
    "\n",
    "\n",
    "8. **Scrape a User's Repositories (GitHub)**: Given someone's GitHub username, can you scrape their GitHub profile to create a list of their repositories with information like repository name, no. of stars, no. of forks, etc.?\n",
    "\n",
    "\n",
    "9. **Bibliography of an Author (Wikipedia)**: The list of books/publications by an author is called their bibliography. Here's an example bibliography page on Wikipedia: https://en.wikipedia.org/wiki/Charles_Dickens_bibliography . Can you scrape this information and create a dataset of [bibliographies](https://en.wikipedia.org/wiki/Category:Bibliographies_by_writer) for popular authors?\n",
    "\n",
    "\n",
    "10. **Country Demographics (Wikipedia)**: Wikipedia provides detailed demographics information for several countries e.g. https://en.wikipedia.org/wiki/Demographics_of_India . Can you scrape these pages to create a dataset of [demographics](https://en.wikipedia.org/wiki/Category:Demographics_by_country) for several countries containing information like population, density, life expectancy, fertility rate, infant mortality rate, age groups, etc.?\n",
    "\n",
    "\n",
    "11. **Stocks Prices (Yahoo Finance)**: Yahoo finance provides detailed information about stocks of publicly listed companies e.g. https://finance.yahoo.com/quote/TWTR . Can you scrape this information to create a dataset of stock prices for popular companies?\n",
    "\n",
    "\n",
    "12. **Create a Dataset of YouTube Videos (YouTube)**: Can you write a program to scrape information about videos from a YouTube channel page e.g. https://www.youtube.com/c/JovianML/videos ? Use this to create a dataset of top videos from popular channels.\n",
    "\n",
    "\n",
    "13. **Songs Dataset (AZLyrics)**: Create a dataset of songs by scraping AZLyrics: https://www.azlyrics.com/f.html . Capture information like song title, artist name, year of release and lyrics URL. \n",
    "\n",
    "\n",
    "14. **Scrape a Popular Blog**: Create a dataset of blog posts on a popular blog e.g. https://m.signalvnoise.com/search/ . The dataset can contain information like the blog title, published date, tags, author, link to blog post, etc.\n",
    "\n",
    "\n",
    "15. **Weekly Top Songs (Top 40 Weekly)**: Create a dataset of the top 40 songs of each week in a given year by scraping the site https://top40weekly.com . Capture information like song title, artist, weekly rank, etc.\n",
    "\n",
    "\n",
    "16. **Video Games Dataset (Steam)**: Create a dataset of popular or trending video games by scraping the listing pages on platforms like Steam: https://store.steampowered.com/genre/Free%20to%20Play/ .\n",
    "\n",
    "Also check out these projects and tutorials: \n",
    "\n",
    "* https://medium.com/@msalmon00/web-scraping-job-postings-from-indeed-96bd588dcb4b\n",
    "* https://medium.com/the-innovation/scraping-medium-with-python-beautiful-soup-3314f898bbf5\n",
    "* https://medium.com/brainstation23/how-to-become-a-pro-with-scraping-youtube-videos-in-3-minutes-a6ac56021961\n",
    "* https://www.freecodecamp.org/news/web-scraping-python-tutorial-how-to-scrape-data-from-a-website/\n",
    "* https://www.freecodecamp.org/news/scraping-wikipedia-articles-with-python/\n",
    "* https://towardsdatascience.com/web-scraping-yahoo-finance-477fe3daa852"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install jovian --upgrade --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jovian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "window.require && require([\"base/js/namespace\"],function(Jupyter){Jupyter.notebook.save_checkpoint()})"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[jovian] Attempting to save notebook..\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "jovian.commit(project=\"python-web-scraping-project-guide\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}